{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä 7 Questions : Construire un agent Text-to-SQL avec GPT-4.1\n",
    "\n",
    "## üá´üá∑ Bienvenue dans ce workshop pratique ! üá¨üáß Welcome to this hands-on workshop!\n",
    "\n",
    "Dans ce notebook, nous allons construire **progressivement** un agent intelligent capable de transformer des questions en langage naturel en requ√™tes SQL, puis d'ex√©cuter ces requ√™tes et m√™me de cr√©er des visualisations.\n",
    "\n",
    "### üéØ Objectifs du workshop\n",
    "- Comprendre les bases du **Text-to-SQL** avec les LLMs\n",
    "- Ma√Ætriser la **sortie structur√©e** avec Pydantic \n",
    "- Impl√©menter un **syst√®me de m√©moire** conversationnelle\n",
    "- Cr√©er un **agent autonome** avec function calling\n",
    "\n",
    "### üõ†Ô∏è Pr√©requis\n",
    "- Python ‚â• 3.10\n",
    "- Une cl√© API OpenAI (GPT-4.1 recommand√©, GPT-4o compatible)\n",
    "- Le fichier `catalogue.csv` dans le m√™me dossier\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Section 1 : Introduction & Setup\n",
    "\n",
    "### Qu'est-ce que le Text-to-SQL ?\n",
    "\n",
    "Le **Text-to-SQL** est une technique qui permet de convertir des questions en langage naturel en requ√™tes SQL. Par exemple :\n",
    "\n",
    "- üó£Ô∏è **Question** : \"Combien d'articles rouges avons-nous ?\"\n",
    "- üîç **SQL g√©n√©r√©** : `SELECT COUNT(*) FROM catalogue WHERE couleur = 'rouge'`\n",
    "\n",
    "### Pourquoi utiliser des agents ?\n",
    "\n",
    "Un **agent** peut encha√Æner plusieurs outils :\n",
    "1. üß† G√©n√©rer du SQL √† partir d'une question\n",
    "2. ‚ö° Ex√©cuter la requ√™te sur la base de donn√©es  \n",
    "3. üìä Cr√©er une visualisation si n√©cessaire\n",
    "4. üí¨ R√©pondre en langage naturel\n",
    "\n",
    "C'est exactement ce que nous allons construire !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Installation des d√©pendances\n",
    "\n",
    "Commen√ßons par installer les biblioth√®ques n√©cessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 1.0.0 not found\n"
     ]
    }
   ],
   "source": [
    "# Installation des d√©pendances\n",
    "!pip install openai>=1.0.0 pandas python-dotenv matplotlib ipython-sql pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë Configuration de la cl√© API OpenAI\n",
    "\n",
    "Vous avez deux options pour d√©finir votre cl√© API :\n",
    "\n",
    "**Option 1 : Fichier .env (recommand√©)**\n",
    "```bash\n",
    "# Cr√©ez un fichier .env dans le m√™me dossier que ce notebook\n",
    "OPENAI_API_KEY=sk-your-key-here\n",
    "```\n",
    "\n",
    "API ressources : \n",
    "- https://platform.openai.com/docs/guides/text?api-mode=chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration termin√©e !\n",
      "ü§ñ Mod√®le utilis√© : gpt-4.1-2025-04-14\n",
      "üîó Connexion √† l'API OpenAI r√©ussie !\n"
     ]
    }
   ],
   "source": [
    "# Imports et configuration\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "\n",
    "# Chargement des variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration du client OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Mod√®le par d√©faut (GPT-4.1)\n",
    "DEFAULT_MODEL = \"gpt-4.1-2025-04-14\"  # Version stable de GPT-4.1\n",
    "# Alternative pour les utilisateurs avec GPT-4o uniquement :\n",
    "# DEFAULT_MODEL = \"gpt-4o\"\n",
    "\n",
    "print(\"‚úÖ Configuration termin√©e !\")\n",
    "print(f\"ü§ñ Mod√®le utilis√© : {DEFAULT_MODEL}\")\n",
    "\n",
    "# Test de la connexion\n",
    "try:\n",
    "    test_response = '...'\n",
    "    \"\"\"\n",
    "    analysez la doc pour faire votre premier appel √† l'API OpenAI \n",
    "    \"\"\"\n",
    "    print(\"üîó Connexion √† l'API OpenAI r√©ussie !\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur de connexion : {e}\")\n",
    "    print(\"üí° V√©rifiez votre cl√© API dans le fichier .env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öôÔ∏è Question 2 : Premi√®re requ√™te ‚Äì l'LLM renvoie du SQL brut\n",
    "\n",
    "### üéØ Objectif\n",
    "Faire en sorte que GPT-4.1 transforme une question en langage naturel en requ√™te SQL pure, sans explication.\n",
    "\n",
    "### üìã √âtapes\n",
    "1. Charger le fichier `catalogue.csv` dans SQLite\n",
    "2. Analyser le sch√©ma de la base de donn√©es  \n",
    "3. Cr√©er un prompt syst√®me optimis√©\n",
    "4. Tester avec une question simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Fichier charg√© : 590 lignes, 9 colonnes\n",
      "üè∑Ô∏è Colonnes : ['external_id', 'reference', 'color', 'tra_value', 'size', 'label', 'ean', 'image', 'price']\n",
      "\n",
      "üîç Aper√ßu des donn√©es :\n",
      "  external_id reference color   tra_value  size           label  \\\n",
      "0  A065H94000     A065H   ALF  variante 7     0  3 BODIES US MC   \n",
      "1  A065H94010     A065H   ALF  variante 7     1  3 BODIES US MC   \n",
      "2  A065H94030     A065H   ALF  variante 7     3  3 BODIES US MC   \n",
      "3  A065H94070     A065H   ALF  variante 7     7  3 BODIES US MC   \n",
      "4  A065H94080     A065H   ALF  variante 7     8  3 BODIES US MC   \n",
      "\n",
      "             ean                                              image  price  \n",
      "0  3666072761781  https://www.petit-bateau.fr/dw/image/v2/BCKL_P...   22.0  \n",
      "1  3666072761798  https://www.petit-bateau.fr/dw/image/v2/BCKL_P...   22.0  \n",
      "2  3666072761828  https://www.petit-bateau.fr/dw/image/v2/BCKL_P...   22.0  \n",
      "3  3666072761811  https://www.petit-bateau.fr/dw/image/v2/BCKL_P...   22.0  \n",
      "4  3666072761835  https://www.petit-bateau.fr/dw/image/v2/BCKL_P...   22.0  \n",
      "\n",
      "‚úÖ Base de donn√©es cr√©√©e avec la table 'catalogue'\n"
     ]
    }
   ],
   "source": [
    "# √âtape 1 : Chargement du catalogue en SQLite\n",
    "def setup_database():\n",
    "    \"\"\"Charge le fichier catalogue.csv dans une base SQLite en m√©moire\"\"\"\n",
    "    \n",
    "    # Lecture du CSV\n",
    "    try:\n",
    "        df = pd.read_csv('catalogue.csv')\n",
    "        print(f\"üìä Fichier charg√© : {len(df)} lignes, {len(df.columns)} colonnes\")\n",
    "        print(f\"üè∑Ô∏è Colonnes : {list(df.columns)}\")\n",
    "        \n",
    "        # Affichage des premi√®res lignes\n",
    "        print(\"\\nüîç Aper√ßu des donn√©es :\")\n",
    "        print(df.head())\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Fichier catalogue.csv non trouv√© !\")\n",
    "        print(\"üí° Assurez-vous qu'il soit dans le m√™me dossier que ce notebook\")\n",
    "        return None, None\n",
    "    \n",
    "    # Cr√©ation de la base SQLite en m√©moire\n",
    "    conn = sqlite3.connect(':memory:')\n",
    "    df.to_sql('catalogue', conn, index=False, if_exists='replace')\n",
    "    \n",
    "    print(f\"\\n‚úÖ Base de donn√©es cr√©√©e avec la table 'catalogue'\")\n",
    "    \n",
    "    return conn, df\n",
    "\n",
    "# Ex√©cution\n",
    "conn, df = setup_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 couleurs les plus fr√©quentes :\n",
      "ZGA: 65\n",
      "ZG9: 52\n",
      "BFQ: 45\n",
      "ZG7: 39\n",
      "FOZ: 25\n"
     ]
    }
   ],
   "source": [
    "# Exemple : Ex√©cuter une requ√™te SQL avec le connecteur conn\n",
    "query = \"VOTRE REQUETE SQL ICI\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "print(\"Top 5 couleurs les plus fr√©quentes :\")\n",
    "for color, count in results:\n",
    "    print(f\"{color}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prenez le temps d'analyser la dataframe df et de comprendre les colonnes disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 2 : Analyse des donn√©es avec OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"\"\"\n",
    "D√©finissez ici le sch√©ma de votre base de donn√©es pour que le LLM puisse l'utiliser.\n",
    "pr√©cisez le nom des colonnes et leurs types, des exemples de donn√©es, etc.\n",
    "\n",
    "output attendu : string\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Prompt syst√®me cr√©√© :\n",
      "==================================================\n",
      "Cr√©e un prompt syst√®me pour la g√©n√©ration de SQL\n"
     ]
    }
   ],
   "source": [
    "# √âtape 3 : Cr√©ation du prompt syst√®me optimis√©\n",
    "def create_text_to_sql_prompt(schema_info):\n",
    "    prompt = \"\"\"Cr√©e un prompt syst√®me pour la g√©n√©ration de SQL\"\"\"\n",
    "        \n",
    "    return prompt\n",
    "\n",
    "# Cr√©ation du prompt\n",
    "text_to_sql_prompt = create_text_to_sql_prompt(schema)\n",
    "print(\"üìù Prompt syst√®me cr√©√© :\")\n",
    "print(\"=\" * 50)\n",
    "print(text_to_sql_prompt[:300] + \"...\" if len(text_to_sql_prompt) > 300 else text_to_sql_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è Question : Donne-moi la requ√™te SQL pour sortir tous les articles rouges\n",
      "============================================================\n",
      "üîç SQL g√©n√©r√© :\n",
      "la bonne query\n",
      "\n",
      "‚ö†Ô∏è La requ√™te pourrait avoir des probl√®mes de syntaxe\n"
     ]
    }
   ],
   "source": [
    "# √âtape 4 : Fonction de g√©n√©ration SQL simple\n",
    "def text_to_sql_basic(question: str) -> str:\n",
    "    \"\"\"Convertit une question en requ√™te SQL avec GPT-4.1.\n",
    "    Utilisez l'api pour requeter OPENAI\"\"\"\n",
    "\n",
    "    sql_query = 'la bonne query'\n",
    "    return sql_query\n",
    "    \n",
    "# Test avec une question simple\n",
    "test_question = \"Donne-moi la requ√™te SQL pour sortir tous les articles rouges\"\n",
    "\n",
    "print(f\"üó£Ô∏è Question : {test_question}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sql_result = text_to_sql_basic(test_question)\n",
    "print(f\"üîç SQL g√©n√©r√© :\")\n",
    "print(sql_result)\n",
    "\n",
    "# Validation rapide de la syntaxe\n",
    "if sql_result.startswith(\"SELECT\") and sql_result.endswith(\";\"):\n",
    "    print(\"\\n‚úÖ La requ√™te semble syntaxiquement correcte !\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è La requ√™te pourrait avoir des probl√®mes de syntaxe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Mini-Quiz : Understanding Text-to-SQL\n",
    "\n",
    "**Question** : Pourquoi demandons-nous √† GPT-4.1 de r√©pondre \"uniquement par la requ√™te SQL\" ?\n",
    "\n",
    "<details>\n",
    "<summary>üí° Cliquez pour voir la r√©ponse</summary>\n",
    "\n",
    "**R√©ponse** : C'est pour avoir une sortie **d√©terministe** et **facile √† traiter programmatiquement**. Si le mod√®le ajoute du texte explicatif, il faudrait le parser pour extraire juste le SQL, ce qui est plus complexe et source d'erreurs.\n",
    "\n",
    "Dans la prochaine section, nous verrons comment **Pydantic** nous permet de structurer encore mieux cette sortie !\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üóÇ Question 3 : Sortie structur√©e avec Pydantic\n",
    "\n",
    "### üéØ Objectif\n",
    "Utiliser **Pydantic** pour valider et structurer la r√©ponse de GPT-4.1, garantissant un format de sortie coh√©rent.\n",
    "\n",
    "### üåü Pourquoi Pydantic ?\n",
    "- ‚úÖ **Validation automatique** des types de donn√©es\n",
    "- üõ°Ô∏è **Gestion d'erreur** robuste  \n",
    "- üèóÔ∏è **Structure pr√©visible** pour notre code\n",
    "- üìö Compatible avec l'API **Structured Outputs** d'OpenAI\n",
    "\n",
    "### üìñ Ressources\n",
    "- [OpenAI Structured Outputs Guide](https://platform.openai.com/docs/guides/structured-outputs)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Sch√©ma Pydantic g√©n√©r√© :\n",
      "========================================\n",
      "{\n",
      "  \"description\": \"Mod\\u00e8le complet pour la r\\u00e9ponse text-to-SQL\\ndefinissez les keys necessaires et les bons types\",\n",
      "  \"properties\": {\n",
      "    \"field1\": {\n",
      "      \"items\": {},\n",
      "      \"title\": \"Field1\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"field2\": {\n",
      "      \"title\": \"Field2\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"query\": {\n",
      "      \"title\": \"Query\",\n",
      "      \"type\": \"integer\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"field1\",\n",
      "    \"field2\",\n",
      "    \"query\"\n",
      "  ],\n",
      "  \"title\": \"TextToSQLResponse\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# D√©finition du mod√®le Pydantic pour la sortie structur√©e\n",
    "class TextToSQLResponse(BaseModel):\n",
    "    \"\"\"Mod√®le complet pour la r√©ponse text-to-SQL\n",
    "    definissez les keys necessaires et les bons types\"\"\"\n",
    "    field1: list\n",
    "    field2 : str\n",
    "    query : int\n",
    "    # A compl√©ter avec les champs n√©cessaires\n",
    " \n",
    "\n",
    "# Affichage du sch√©ma JSON pour comprendre la structure\n",
    "print(\"üìã Sch√©ma Pydantic g√©n√©r√© :\")\n",
    "print(\"=\" * 40)\n",
    "print(json.dumps(TextToSQLResponse.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cr√©e un prompt syst√®me pour la g√©n√©ration de SQL'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rappel\n",
    "text_to_sql_prompt[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette question, utiliser le endpoint decrit dans cette doc :\n",
    "- https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sql_structured(question: str) -> TextToSQLResponse:\n",
    "    response = client.responses.parse(\n",
    "       # a completer\n",
    "    )\n",
    "    return response.output_parsed\n",
    "\n",
    "# Test de la fonction structur√©e\n",
    "test_question = \"Combien d'articles de couleur bleue avons-nous ?\"\n",
    "\n",
    "print(f\"üó£Ô∏è Question : {test_question}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "structured_result = text_to_sql_structured(test_question)\n",
    "\n",
    "print(f\"üîç Requ√™te SQL : {structured_result.query}\")\n",
    "\n",
    "# Validation du type\n",
    "print(f\"\\n‚úÖ Type de retour : {type(structured_result)}\")\n",
    "print(f\"üèóÔ∏è Validation Pydantic : {'R√©ussie' if structured_result.query else '√âchou√©e'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_result.query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison entre l'approche basique et structur√©e\n",
    "print(\"üî¨ COMPARAISON DES DEUX APPROCHES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_questions = [\n",
    "    \"Quels sont les 5 articles les plus chers ?\",\n",
    "    \"Donne-moi la moyenne des prix par cat√©gorie\",\n",
    "    \"Combien d'articles contiennent le mot 'premium' ?\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nüìù Test {i}: {question}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Approche basique\n",
    "    basic_result = text_to_sql_basic(question)\n",
    "    print(f\"üü° Basique: {basic_result}\")\n",
    "    \n",
    "    # Approche structur√©e  \n",
    "    struct_result = text_to_sql_structured(question)\n",
    "    print(f\"üü¢ Structur√©e: {struct_result.query}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_result.model_dump_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß† Question 4 : Adding Memory (Conversation History)\n",
    "\n",
    "### üéØ Objectif  \n",
    "Maintenir un **historique de conversation** pour que l'agent puisse se souvenir des interactions pr√©c√©dentes et fournir des r√©ponses plus contextuelles.\n",
    "\n",
    "Exemple : \n",
    "- Quels sont les articles rouges?\n",
    "- Combien valent plus de 20 Euros?\n",
    "\n",
    "### üîÑ Pourquoi la m√©moire est importante ?\n",
    "- **Continuit√©** : \"Maintenant trie par prix\" fait r√©f√©rence √† la requ√™te pr√©c√©dente\n",
    "- **Contexte** : L'agent comprend les questions de suivi\n",
    "- **Exp√©rience utilisateur** : Conversation plus naturelle\n",
    "\n",
    "### üí° Approche\n",
    "Maintenir une liste de messages qui grandit au fil de la conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent conversationnel initialis√© !\n",
      "üìä √âtat initial : Conversation: 1 messages, 0 requ√™tes g√©n√©r√©es\n"
     ]
    }
   ],
   "source": [
    "# Classe pour g√©rer la m√©moire conversationnelle\n",
    "class ConversationalSQLAgent:\n",
    "    \"\"\"Agent Text-to-SQL avec m√©moire conversationnelle\"\"\"\n",
    "    \n",
    "    def __init__(self, system_prompt: str):\n",
    "        # Ajoute une consigne pour la prise en compte du contexte conversationnel\n",
    "        #TODO\n",
    "        historical_prompt = (\n",
    "            system_prompt\n",
    "            + \"AJUSTER LE SYSTEME PROMPT POUR PRENDRE EN COMPTE L'HISTORIQUE DE LA CONVERSATION\"\n",
    "        )\n",
    "        self.system_prompt = historical_prompt\n",
    "        self.conversation_history = [\n",
    "            {\"role\": \"system\", \"content\": historical_prompt}\n",
    "            # tous les autres messages seront ajout√©s ici sous la forme de dictionnaires en precisant le role\n",
    "            # message de l'utilisatuer : user, reponse de l'AI : assistant\n",
    "        ]\n",
    "        self.query_count = 0\n",
    "    \n",
    "    def add_user_message(self, message: str):\n",
    "        \"\"\"Ajoute un message utilisateur √† l'historique - ATTENTION A BIEN PRECISER LE ROLE USER DANS LE DICT\"\"\"\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    def add_assistant_message(self, message: str):\n",
    "        \"\"\"Ajoute une r√©ponse de l'assistant √† l'historique\"\"\"\n",
    "        #TODO\n",
    "    \n",
    "    def generate_sql(self, question: str) -> TextToSQLResponse:\n",
    "        #TODO\n",
    "        \"\"\"G√©n√®re du SQL en tenant compte de l'historique\"\"\"\n",
    "        \n",
    "        # Ajouter la question actuelle de l'utilisateur √† l'historique\n",
    "        self.add_user_message(question)\n",
    "        \n",
    "        try:\n",
    "            # Utilise la fonction structur√©e pour obtenir la r√©ponse.\n",
    "            # L'historique est a jour avec la toute derniere question de l;utilisateur\n",
    "            structured_result = client.responses.parse(...         #TODO\n",
    "            \n",
    "            # sauve la reponse du LLM dans l'historique en mode assistant. Ne pas oublier de formatter le BAseModel en JSON \n",
    "            self.add_assistant_message(structured_result.model_dump_json())\n",
    "            self.query_count += 1\n",
    "            return structured_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_response = TextToSQLResponse(\n",
    "                query=\"SELECT 1; -- Erreur\"\n",
    "            )\n",
    "            self.add_assistant_message(error_response.model_dump_json())\n",
    "            return error_response\n",
    "    \n",
    "    def get_history_summary(self) -> str:\n",
    "        \"\"\"R√©sum√© de l'historique de conversation\"\"\"\n",
    "        return f\"Conversation: {len(self.conversation_history)} messages, {self.query_count} requ√™tes g√©n√©r√©es\"\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Remet √† z√©ro l'historique (garde le prompt syst√®me)\"\"\"\n",
    "        self.conversation_history = [self.conversation_history[0]]  # Garde seulement le syst√®me\n",
    "        self.query_count = 0\n",
    "\n",
    "# Initialisation de l'agent conversationnel\n",
    "conversational_agent = ConversationalSQLAgent(text_to_sql_prompt)\n",
    "print(\"ü§ñ Agent conversationnel initialis√© !\")\n",
    "print(f\"üìä √âtat initial : {conversational_agent.get_history_summary()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la m√©moire conversationnelle avec reset\n",
    "print(\"üé≠ D√âMONSTRATION DE LA M√âMOIRE CONVERSATIONNELLE (avec reset)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# S√©quence de questions qui s'appuie sur le contexte\n",
    "conversation_sequence = [\n",
    "    \"Montre-moi tous les articles plus chers que 20 euros\",\n",
    "    \"Maintenant trie-les par prix d√©croissant\", \n",
    "    \"Limite √† 3 r√©sultats\",\n",
    "    \"Ajoute aussi les articles bleus √† cette s√©lection\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(conversation_sequence, 1):\n",
    "    print(f\"\\nüí¨ Question {i}: {question}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    result = conversational_agent.generate_sql(question)\n",
    "    \n",
    "    print(f\"üîç SQL: {result.query}\")\n",
    "    print(f\"üìù Historique: {conversational_agent.get_history_summary()}\")\n",
    "    \n",
    "\n",
    "    # teste manuellement l'ex√©cution de la requ√™te SQL - pour verifier la validit√©\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(result.query)\n",
    "        rows = cursor.fetchall()\n",
    "        print(f\"‚úÖ Ex√©cution r√©ussie: {len(rows)} r√©sultats\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur d'ex√©cution: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ Maintenant, on va faire quelque chose de nouveau : on r√©initialise la m√©moire de l'agent !\")\n",
    "conversational_agent.clear_history()\n",
    "print(f\"üßπ Historique apr√®s reset: {conversational_agent.get_history_summary()}\")\n",
    "\n",
    "# Nouvelle s√©quence de questions ind√©pendantes\n",
    "new_questions = [\n",
    "    \"Combien d'articles co√ªtent moins de 10 euros ?\",\n",
    "    \"Quels sont les 2 articles les moins chers ?\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(new_questions, 1):\n",
    "    print(f\"\\nüí¨ Nouvelle question {i}: {question}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    result = conversational_agent.generate_sql(question)\n",
    "    \n",
    "    print(f\"üîç SQL: {result.query}\")\n",
    "    print(f\"üìù Historique: {conversational_agent.get_history_summary()}\")\n",
    "    \n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(result.query)\n",
    "        rows = cursor.fetchall()\n",
    "        print(f\"‚úÖ Ex√©cution r√©ussie: {len(rows)} r√©sultats\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur d'ex√©cution: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ BILAN FINAL\")\n",
    "print(f\"üìä {conversational_agent.get_history_summary()}\")\n",
    "print(\"‚ú® L'agent a bien r√©initialis√© et g√©r√© deux contextes s√©par√©s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Question 5 : Function / Tool Calling\n",
    "\n",
    "### üéØ Objectif\n",
    "Impl√©menter le **Function Calling** (Tool Calling) d'OpenAI pour que l'agent puisse :\n",
    "1. üß† **G√©n√©rer** des requ√™tes SQL (`make_sql`)\n",
    "2. ‚ö° **Ex√©cuter** les requ√™tes sur la base (`run_query`)\n",
    "\n",
    "### üõ†Ô∏è Concept de Function Calling\n",
    "Le mod√®le GPT-4.1 peut d√©cider quand et comment utiliser des outils externes. Il re√ßoit une description des outils disponibles et choisit lequel utiliser en fonction du contexte.\n",
    "\n",
    "### üìö Flux de travail\n",
    "1. **Question utilisateur** : \"Combien d'articles rouges ?\"\n",
    "2. **GPT-4.1 d√©cide** : J'ai besoin de `make_sql` \n",
    "3. **Ex√©cution** : L'outil g√©n√®re `SELECT COUNT(*) FROM catalogue WHERE couleur = 'rouge';`\n",
    "\n",
    "--- \n",
    "1. **Question utilisateur** : \"execute la query SELECT * FROM TABLE\"\n",
    "2. **GPT-4.1 d√©cide** : J'ai besoin de runner `run_query_tool` \n",
    "3. **Ex√©cution** : L'outil execute la function avec l'argument `SELECT * FROM TABLE;`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ressources : \n",
    "- https://platform.openai.com/docs/guides/function-calling?api-mode=chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des outils (tools) disponibles pour l'agent\n",
    "\n",
    "def make_sql_tool(question: str) -> str:\n",
    "    #TODO\n",
    "\n",
    "def run_query_tool(sql_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Outil : Ex√©cute une requ√™te SQL sur la base de donn√©es\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    df_result = pd.DataFrame(rows, columns=columns)\n",
    "    \n",
    "    if len(df_result) == 0:\n",
    "        return \"Aucun r√©sultat trouv√©.\"\n",
    "    elif len(df_result) <= 10:\n",
    "        return f\"R√©sultats ({len(df_result)} lignes):\\\\n{df_result.to_string(index=False)}\"\n",
    "    else:\n",
    "        return f\"R√©sultats ({len(df_result)} lignes, affichage des 10 premi√®res):\\\\n{df_result.head(10).to_string(index=False)}\"\n",
    "\n",
    "\n",
    "# D√©finition des outils au format OpenAI Function Calling\n",
    "tools_definition = [\n",
    "   #TODO\n",
    "]\n",
    "\n",
    "print(\"üîß Outils d√©finis avec succ√®s !\")\n",
    "print(\"üìã Outils disponibles :\")\n",
    "for tool in tools_definition:\n",
    "    func = tool[\"function\"]\n",
    "    print(f\"  ‚Ä¢ {func['name']}: {func['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent avec Function Calling\n",
    "class ToolCallingAgent:\n",
    "    \"\"\"Agent qui utilise les outils via Function Calling \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tools = tools_definition\n",
    "        self.conversation_history = []\n",
    "        self.available_functions = {\n",
    "            \"make_sql\": make_sql_tool,\n",
    "            \"run_query\": run_query_tool\n",
    "        }\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"Interface principale pour discuter avec l'agent \"\"\"\n",
    "        \n",
    "        # Ajouter le message utilisateur\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        # Prompt syst√®me pour l'agent\n",
    "        #TODO\n",
    "        system_prompt = f\"\"\"modifier le systemen prompt pour prendre en compte les outils disponibles\"\"\"\n",
    "        \n",
    "        # Pr√©parer les messages avec le syst√®me\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + self.conversation_history\n",
    "        \n",
    "        try:\n",
    "            # Appel initial avec les outils\n",
    "            response = client.chat.completions.create(\n",
    "                #TODO\n",
    "            )\n",
    "            \n",
    "            response_message = response.choices[0].message\n",
    "            \n",
    "            # V√©rifier si le mod√®le veut utiliser des outils\n",
    "            if response_message.tool_calls:\n",
    "                # Ajouter la r√©ponse du mod√®le √† l'historique\n",
    "                self.conversation_history.append({\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": response_message.content,\n",
    "                    \"tool_calls\": response_message.tool_calls\n",
    "                })\n",
    "                \n",
    "                # Ex√©cuter chaque outil demand√©\n",
    "                for tool_call in response_message.tool_calls:\n",
    "                    function_name = #get the function name from the tool call\n",
    "                    function_args = #get the json args from the tool call\n",
    "                    \n",
    "                    print(f\"üîß Utilisation de l'outil : {function_name}\")\n",
    "                    print(f\"üì• Arguments : {function_args}\")\n",
    "                    \n",
    "                    # Ex√©cuter la fonction\n",
    "                    if function_name in self.available_functions:\n",
    "                        function_result = self.available_functions[function_name](**function_args)\n",
    "                        print(f\"üì§ R√©sultat : {function_result[:100]}{'...' if len(str(function_result)) > 100 else ''}\")\n",
    "                        \n",
    "                        # Ajouter le r√©sultat √† l'historique\n",
    "                        self.conversation_history.append({\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"role\": \"tool\", \n",
    "                            \"name\": function_name,\n",
    "                            \"content\": str(function_result)\n",
    "                        })\n",
    "                \n",
    "                # Nouvel appel pour obtenir la r√©ponse finale\n",
    "                final_response = client.chat.completions.create(\n",
    "                    #prendre en compte l'historique mis √† jour avec la derniere reponse de l'outil\n",
    "                )\n",
    "                \n",
    "                final_message = final_response.choices[0].message.content\n",
    "                self.conversation_history.append({\"role\": \"assistant\", \"content\": final_message})\n",
    "                \n",
    "                return final_message\n",
    "            \n",
    "            else:\n",
    "                # Pas d'outils utilis√©s, r√©ponse directe\n",
    "                self.conversation_history.append({\"role\": \"assistant\", \"content\": response_message.content})\n",
    "                return response_message.content\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Erreur lors du traitement : {e}\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
    "            return error_msg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de l'agent avec tools\n",
    "tool_agent = ToolCallingAgent()\n",
    "print(\"ü§ñ Agent avec Function Calling initialis√© !\")\n",
    "\n",
    "# Test du Function Calling avec un dialogue complet\n",
    "print(\"üé™ D√âMONSTRATION DU FUNCTION CALLING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_questions = [\n",
    "    \"donne moi la query pour sortir tous les articles plus chers que 15 euros\",\n",
    "    \"execute la query SELECT * FROM catalogue ORDER BY price ASC LIMIT 2;\",\n",
    "    \"Combien d'articles rouges avons-nous ?\",\n",
    "    \"Parmi ceux la, donne moi les 3 articles les plus chers\",\n",
    "]\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nüó£Ô∏è Question {i}: {question}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    response = tool_agent.chat(question)\n",
    "    \n",
    "    print(f\"\\nü§ñ R√©ponse finale:\")\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Question 6 : Building a Simple Agent Loop\n",
    "\n",
    "### üéØ Objectif\n",
    "Cr√©er un **agent autonome** qui tourne en boucle et peut traiter plusieurs demandes de l'utilisateur de mani√®re interactive.\n",
    "\n",
    "### üîÑ Concept d'Agent Loop\n",
    "Un agent en boucle peut :\n",
    "- Attendre des commandes utilisateur\n",
    "- Traiter les demandes de mani√®re autonome\n",
    "- Maintenir le contexte entre les interactions\n",
    "- G√©rer les erreurs gracieusement\n",
    "- Permettre √† l'utilisateur de sortir proprement\n",
    "\n",
    "Exemple : quels sont les articles a moins de 30 Euros ?\n",
    "- generer une query\n",
    "- executer la query\n",
    "- repondre a l'utilisateur\n",
    "\n",
    "On est plus limite a un seul call de fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent avec Function Calling am√©lior√© : boucle jusqu'√† satisfaction de la requ√™te utilisateur\n",
    "class ToolCallingAgent:\n",
    "    \"\"\"Agent qui utilise les outils via Function Calling, avec boucle jusqu'√† r√©sultat final\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tools = tools_definition\n",
    "        self.conversation_history = []\n",
    "        self.available_functions = {\n",
    "            \"make_sql\": make_sql_tool,\n",
    "            \"run_query\": run_query_tool\n",
    "        }\n",
    "\n",
    "    def reset_history(self):\n",
    "        \"\"\"R√©initialise l'historique de conversation\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"üßπ Historique r√©initialis√© !\")\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"Interface principale pour discuter avec l'agent (boucle jusqu'√† r√©ponse finale)\"\"\"\n",
    "\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "        system_prompt = \" Definir le systeme prompt pour l'agent manager qui va appeler les differents outils \" \\\n",
    "        \"successivement jusqu'√† obtenir une r√©ponse satisfaisante. \" \n",
    "\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + self.conversation_history\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                response = client.chat.completions.create(\n",
    "                   #TODO: utiliser le mod√®le et les messages avec les outils disponibles\n",
    "                )\n",
    "                response_message = response.choices[0].message\n",
    "\n",
    "                # Si le mod√®le demande un ou plusieurs outils\n",
    "                if getattr(response_message, \"tool_calls\", None):\n",
    "                    self.conversation_history.append({\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": response_message.content,\n",
    "                        \"tool_calls\": response_message.tool_calls\n",
    "                    })\n",
    "                    for tool_call in response_message.tool_calls:\n",
    "                        function_name = # TODO get the function name from the tool call\n",
    "                        function_args = # TODO get the json args from the tool call\n",
    "                        print(f\"üîß Utilisation de l'outil : {function_name}\")\n",
    "                        print(f\"üì• Arguments : {function_args}\")\n",
    "\n",
    "                        if function_name in self.available_functions:\n",
    "                            function_result = self.available_functions[function_name](**function_args)\n",
    "                            print(f\"üì§ R√©sultat : {str(function_result)[:100]}{'...' if len(str(function_result)) > 100 else ''}\")\n",
    "                            self.conversation_history.append({\n",
    "                                \"tool_call_id\": tool_call.id,\n",
    "                                \"role\": \"tool\",\n",
    "                                \"name\": function_name,\n",
    "                                \"content\": str(function_result)\n",
    "                            })\n",
    "                    # Rafra√Æchir les messages pour la prochaine boucle\n",
    "                    messages = [{\"role\": \"system\", \"content\": system_prompt}] + self.conversation_history\n",
    "                    continue  # Boucle tant qu'il y a des tool_calls\n",
    "\n",
    "                # Si pas d'outils demand√©s, r√©ponse finale\n",
    "                self.conversation_history.append({\"role\": \"assistant\", \"content\": response_message.content})\n",
    "                return response_message.content\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Erreur lors du traitement : {e}\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
    "            return error_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_agent = ToolCallingAgent()\n",
    "\n",
    "# Test automatique de l'agent (simulation d'une session)\n",
    "print(\"üé≠ SIMULATION D'UNE SESSION INTERACTIVE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Simulation de commandes utilisateur\n",
    "simulated_session = [\n",
    "    \"Combien d'articles avons-nous au total ?\",\n",
    "    \"Montre-moi les articles contenant le mot 'bodies'\",\n",
    "    \"Parmi ces articles, quels sont les 3 plus chers ?\",\n",
    "]\n",
    "\n",
    "print(\"ü§ñ D√©marrage de la simulation...\")\n",
    "print(\"üìù Commandes √† tester :\", simulated_session)\n",
    "print(\"\\\\n\" + \"=\" * 40)\n",
    "\n",
    "for i,msg in enumerate(simulated_session):\n",
    "    print('')\n",
    "    print('')\n",
    "    print(f\"\\\\nüé¨ Simulation {i}: {msg}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Traitement de la commande\n",
    "    agent_answer = interactive_agent.chat(msg)\n",
    "    print(f\"ü§ñ R√©ponse de l'agent : {agent_answer}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if not agent_answer:\n",
    "        print(\"‚ö†Ô∏è L'agent a demand√© l'arr√™t\")\n",
    "        break\n",
    "\n",
    "print(\"\\\\nüé¨ Fin de la simulation\")\n",
    "print(\"üí° Pour une session r√©elle, ex√©cutez : interactive_agent.run_interactive_loop()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_agent = ToolCallingAgent()\n",
    "\n",
    "# Test automatique de l'agent (simulation d'une session)\n",
    "print(\"üé≠ SIMULATION D'UNE SESSION INTERACTIVE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Simulation de commandes utilisateur\n",
    "simulated_session = [\n",
    "    \"regarde successivement le nombre d'articles par couleur, puis la couleur de l'article le plus cher, et enfin les articles de cette couleur. \",\n",
    "]\n",
    "\n",
    "print(\"ü§ñ D√©marrage de la simulation...\")\n",
    "print(\"üìù Commandes √† tester :\", simulated_session)\n",
    "print(\"\\\\n\" + \"=\" * 40)\n",
    "\n",
    "for i,msg in enumerate(simulated_session):\n",
    "    print(f\"\\\\nüé¨ Simulation {i}: {msg}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Traitement de la commande\n",
    "    should_continue = interactive_agent.chat(msg)\n",
    "    \n",
    "    if not should_continue:\n",
    "        print(\"‚ö†Ô∏è L'agent a demand√© l'arr√™t\")\n",
    "        break\n",
    "\n",
    "print(\"\\\\nüé¨ Fin de la simulation\")\n",
    "print(\"üí° Pour une session r√©elle, ex√©cutez : interactive_agent.run_interactive_loop()\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Question 7 : Simplify it using the Agents SDK\n",
    "\n",
    "\n",
    "Benefices: \n",
    " - Gestion automatique du contexte\n",
    " - Gestion automatique de la boucle de l'agent, on definit uniquement les tools \n",
    "\n",
    "Resources : \n",
    "- https://openai.github.io/openai-agents-python/\n",
    "- https://github.com/openai/openai-agents-python/blob/main/examples/basic/tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, function_tool\n",
    "import pandas as pd  # Ensure this is imported\n",
    "import asyncio\n",
    "\n",
    "# Assume conn and text_to_sql_structured are globally available\n",
    "# e.g. conn = sqlite3.connect('your_db.sqlite') or similar\n",
    "\n",
    "@function_tool\n",
    "def make_sql(question: str) -> str:\n",
    "    # TODO\n",
    "\n",
    "@function_tool\n",
    "def run_query(sql_query: str) -> str:\n",
    "   #TODO\n",
    "\n",
    "# Define the agent\n",
    "sql_agent = Agent(\n",
    "    name=\"SQL Assistant\",\n",
    "    instructions=(\n",
    "        \"your system prompt manager here\"\n",
    "    ),\n",
    "    tools=[make_sql, run_query],\n",
    ")\n",
    "\n",
    "result = await Runner.run(sql_agent, \"how many items below 10 euros do we have? \")  # type: ignore[top-level-await]  # noqa: F704\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing streamed items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run starting ===\n",
      "Agent updated: SQL Assistant\n",
      "-- Tool called: make_sql\n",
      "   With input: {\"question\":\"how many items below 10 euros do we have?\"}\n",
      "\n",
      "-- Tool output: SELECT COUNT(*) FROM catalogue WHERE price < 10;\n",
      "\n",
      "-- Tool called: run_query\n",
      "   With input: {\"sql_query\":\"SELECT COUNT(*) FROM catalogue WHERE price < 10;\"}\n",
      "\n",
      "-- Tool output: R√©sultats (1 lignes):\n",
      " COUNT(*)\n",
      "        3\n",
      "\n",
      "-- Message output:\n",
      "We have 3 items priced below 10 euros.\n",
      "\n",
      "=== Run complete ===\n",
      "==========\n",
      "==========\n",
      "=== Run starting ===\n",
      "Agent updated: SQL Assistant\n",
      "-- Tool called: make_sql\n",
      "   With input: {\"question\":\"How many products are red?\"}\n",
      "\n",
      "-- Tool output: SELECT COUNT(*) FROM catalogue WHERE color LIKE '%red%';\n",
      "\n",
      "-- Tool called: run_query\n",
      "   With input: {\"sql_query\":\"SELECT COUNT(*) FROM catalogue WHERE color LIKE '%red%';\"}\n",
      "\n",
      "-- Tool output: R√©sultats (1 lignes):\n",
      " COUNT(*)\n",
      "        0\n",
      "\n",
      "-- Message output:\n",
      "There are no red products in the catalog.\n",
      "\n",
      "=== Run complete ===\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "from agents import Agent, Runner, function_tool, ItemHelpers\n",
    "\n",
    "# Assume conn and text_to_sql_structured are defined globally\n",
    "# e.g. conn = sqlite3.connect('your_db.sqlite')\n",
    "\n",
    "\n",
    "async def main(input_query):\n",
    "    sql_agent = Agent(\n",
    "        name=\"SQL Assistant\",\n",
    "        instructions=(\n",
    "        \"your system prompt manager here\"\n",
    "    ),\n",
    "        tools=[make_sql, run_query],\n",
    "    )\n",
    "\n",
    "    result = Runner.run_streamed(sql_agent,input_query)\n",
    "    \n",
    "    print(\"=== Run starting ===\")\n",
    "    async for event in result.stream_events():\n",
    "        if event.type == \"raw_response_event\":\n",
    "            continue\n",
    "        elif event.type == \"agent_updated_stream_event\":\n",
    "            print(f\"Agent updated: {event.new_agent.name}\")\n",
    "        elif event.type == \"run_item_stream_event\":\n",
    "            item = event.item\n",
    "            if item.type == \"tool_call_item\":\n",
    "                print(f\"-- Tool called: {item.raw_item.name}\")\n",
    "                print(f\"   With input: {item.raw_item.arguments}\")\n",
    "            elif item.type == \"tool_call_output_item\":\n",
    "                print(f\"-- Tool output: {item.output}\")\n",
    "            elif item.type == \"message_output_item\":\n",
    "                print(f\"-- Message output:\\n{ItemHelpers.text_message_output(item)}\")\n",
    "            print('')\n",
    "    print(\"=== Run complete ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main(\"how many items below 10 euros do we have? \"))  # type: ignore[top-level-await]  # noqa: F704\n",
    "    print('==========')\n",
    "    print('==========')\n",
    "\n",
    "    asyncio.run(main(\"how many of them are red? \"))  # type: ignore[top-level-await]  # noqa: F704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintainting conversation context between two conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing: how many items below 10 euros do we have? ===\n",
      "Agent updated: SQL Assistant\n",
      "-- Tool called: make_sql\n",
      "   With input: {\"question\":\"How many items are priced below 10 euros in the product catalog?\"}\n",
      "\n",
      "-- Tool output: SELECT COUNT(*) FROM catalogue WHERE price < 10;\n",
      "\n",
      "-- Tool called: run_query\n",
      "   With input: {\"sql_query\":\"SELECT COUNT(*) FROM catalogue WHERE price < 10;\"}\n",
      "\n",
      "-- Tool output: R√©sultats (1 lignes):\n",
      " COUNT(*)\n",
      "        3\n",
      "\n",
      "-- Message output:\n",
      "We have 3 items priced below 10 euros in the catalog.\n",
      "\n",
      "=== Processing Complete ===\n",
      "=== Processing: how many of them are red? ===\n",
      "Agent updated: SQL Assistant\n",
      "-- Tool called: make_sql\n",
      "   With input: {\"question\":\"How many red items are priced below 10 euros in the product catalog?\"}\n",
      "\n",
      "-- Tool called: make_sql\n",
      "   With input: {\"question\":\"How many red items are in the product catalog?\"}\n",
      "\n",
      "-- Tool output: SELECT COUNT(*) FROM catalogue WHERE color LIKE '%red%' AND price < 10;\n",
      "\n",
      "-- Tool output: SELECT COUNT(*) FROM catalogue WHERE color LIKE '%red%';\n",
      "\n",
      "-- Tool called: run_query\n",
      "   With input: {\"sql_query\":\"SELECT COUNT(*) FROM catalogue WHERE color LIKE '%red%' AND price < 10;\"}\n",
      "\n",
      "-- Tool called: run_query\n",
      "   With input: {\"sql_query\":\"SELECT COUNT(*) FROM catalogue WHERE color LIKE '%red%';\"}\n",
      "\n",
      "-- Tool output: R√©sultats (1 lignes):\n",
      " COUNT(*)\n",
      "        0\n",
      "\n",
      "-- Tool output: R√©sultats (1 lignes):\n",
      " COUNT(*)\n",
      "        0\n",
      "\n",
      "-- Message output:\n",
      "There are no red items priced below 10 euros in the catalog.\n",
      "\n",
      "=== Processing Complete ===\n",
      "=== Processing: what about blue ones? ===\n",
      "Agent updated: SQL Assistant\n",
      "-- Tool called: make_sql\n",
      "   With input: {\"question\":\"How many blue items are priced below 10 euros in the product catalog?\"}\n",
      "\n",
      "-- Tool output: SELECT COUNT(*) FROM catalogue WHERE color LIKE '%blue%' AND price < 10;\n",
      "\n",
      "-- Tool called: run_query\n",
      "   With input: {\"sql_query\":\"SELECT COUNT(*) FROM catalogue WHERE color LIKE '%blue%' AND price < 10;\"}\n",
      "\n",
      "-- Tool output: R√©sultats (1 lignes):\n",
      " COUNT(*)\n",
      "        0\n",
      "\n",
      "-- Message output:\n",
      "There are no blue items priced below 10 euros in the catalog.\n",
      "\n",
      "=== Processing Complete ===\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Create a conversation manager class\n",
    "class ConversationManager:\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    async def ask(self, question):\n",
    "        # Add the new user message to conversation history\n",
    "        if self.conversation_history:\n",
    "            new_input = self.conversation_history + [{\"role\": \"user\", \"content\": question}]\n",
    "        else:\n",
    "            new_input = question\n",
    "        \n",
    "        print(f\"=== Processing: {question} ===\")\n",
    "        result = Runner.run_streamed(self.agent, new_input)\n",
    "        \n",
    "        async for event in result.stream_events():\n",
    "            if event.type == \"raw_response_event\":\n",
    "                continue\n",
    "            elif event.type == \"agent_updated_stream_event\":\n",
    "                print(f\"Agent updated: {event.new_agent.name}\")\n",
    "            elif event.type == \"run_item_stream_event\":\n",
    "                item = event.item\n",
    "                if item.type == \"tool_call_item\":\n",
    "                    print(f\"-- Tool called: {item.raw_item.name}\")\n",
    "                    print(f\"   With input: {item.raw_item.arguments}\")\n",
    "                elif item.type == \"tool_call_output_item\":\n",
    "                    print(f\"-- Tool output: {item.output}\")\n",
    "                elif item.type == \"message_output_item\":\n",
    "                    print(f\"-- Message output:\\n{ItemHelpers.text_message_output(item)}\")\n",
    "                print('')\n",
    "        \n",
    "        # Update conversation history for next turn\n",
    "        self.conversation_history = result.to_input_list()\n",
    "        print(\"=== Processing Complete ===\")\n",
    "        return result\n",
    "\n",
    "async def main_with_manager():\n",
    "    sql_agent = Agent(\n",
    "        name=\"SQL Assistant\",\n",
    "        instructions=(\n",
    "            \"You are an expert SQL assistant helping to analyze a product catalog database.\\n\"\n",
    "            \"Use the 'make_sql' tool to generate SQL queries from questions.\\n\"\n",
    "            \"Use the 'run_query' tool to execute SQL queries.\\n\"\n",
    "            \"Iterate as needed until you can provide a final answer to the user.\"\n",
    "        ),\n",
    "        tools=[make_sql, run_query],\n",
    "    )\n",
    "    \n",
    "    conversation = ConversationManager(sql_agent)\n",
    "    \n",
    "    # Now these calls will maintain context\n",
    "    await conversation.ask(\"how many items below 10 euros do we have?\")\n",
    "    await conversation.ask(\"how many of them are red?\")\n",
    "    await conversation.ask(\"what about blue ones?\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    # Option 2: Using conversation manager\n",
    "    asyncio.run(main_with_manager())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéä F√©licitations ! Workshop termin√© avec succ√®s !\n",
    "\n",
    "### üèÜ Ce que vous avez accompli\n",
    "\n",
    "1. **üìñ Compr√©hension des bases** : Text-to-SQL, agents, et GPT-4.1\n",
    "2. **‚öôÔ∏è G√©n√©ration SQL** : Conversion de langage naturel en requ√™tes SQL\n",
    "3. **üóÇ Sortie structur√©e** : Validation robuste avec Pydantic\n",
    "4. **üß† M√©moire conversationnelle** : Contexte persistant entre les interactions\n",
    "5. **üîß Function Calling** : Outils autonomes pour SQL et ex√©cution  \n",
    "6. **ü§ñ Agent en boucle** : Interface interactive compl√®te\n",
    "7. **üìä Openai Agents SDK ** : Comments Simplifier le code\n",
    "\n",
    "### üöÄ Comment utiliser votre agent\n",
    "\n",
    "```python\n",
    "# Agent simple (questions individuelles)\n",
    "response = advanced_agent.chat(\"Montre-moi un graphique des ventes par r√©gion\")\n",
    "\n",
    "# Agent interactif (session compl√®te)\n",
    "interactive_agent = InteractiveAgent()\n",
    "interactive_agent.run_interactive_loop()\n",
    "```\n",
    "\n",
    "### üí° Extensions possibles\n",
    "\n",
    "- **üåê API REST** : Exposer l'agent via FastAPI\n",
    "- **üîê Authentification** : Gestion des utilisateurs\n",
    "- **üíæ Persistance** : Sauvegarde de l'historique\n",
    "- **üìà Analytics** : M√©triques d'usage de l'agent\n",
    "- **üé® Interface Web** : Frontend avec Streamlit ou React\n",
    "\n",
    "### üìö Ressources pour aller plus loin\n",
    "\n",
    "- **OpenAI Function Calling** : [Documentation officielle](https://platform.openai.com/docs/guides/function-calling)\n",
    "- **Pydantic V2** : [Guide complet](https://docs.pydantic.dev/latest/)\n",
    "- **Text-to-SQL avanc√©** : Recherchez \"few-shot learning\" et \"RAG pour SQL\"\n",
    "\n",
    "---\n",
    "\n",
    "**üéØ Merci d'avoir suivi ce workshop ! Vous ma√Ætrisez maintenant la cr√©ation d'agents Text-to-SQL avec GPT-4.1.**\n",
    "\n",
    "*üë®‚Äçüíª Happy coding! üöÄ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
